{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDs_DEatdyXK",
        "outputId": "6d97dba8-ef91-4311-b21c-e4670c2ebcae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Omitted Part"
      ],
      "metadata": {
        "id": "EIJF4xQSzzN1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imvYdIYq5uXn"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_spectrogram(audio_path, output_path):\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "    D = np.abs(librosa.stft(y))\n",
        "    D_db = librosa.amplitude_to_db(D, ref=np.max)\n",
        "    fig, ax = plt.subplots(figsize=(28, 5))\n",
        "    ax.axis('off')\n",
        "    librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='log', ax=ax)\n",
        "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "# Path to the WAV file\n",
        "wav_file_path = \"/content/drive/MyDrive/AUDIO/New Model_Main/Real_40/Copy of YONGEY_MINGYU_part8.wav\"\n",
        "\n",
        "# Output path for the spectrogram image\n",
        "output_img_path = \"/content/drive/MyDrive/AUDIO/New Model_Main/Spectro_img/Real/Copy of YONGEY_MINGYU_part8.png\"\n",
        "\n",
        "# Create the spectrogram image\n",
        "create_spectrogram(wav_file_path, output_img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "h1UQYsvyH48K",
        "outputId": "2906a4e5-2a81-4307-ca64-34d214be6294"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5f9a4ca2e08d>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Preprocess real audio files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mpreprocess_and_save_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/AUDIO/New Model_Main/Real_40'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/MyDrive/AUDIO/New Model_Main/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Spectrogram images generated successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-5f9a4ca2e08d>\u001b[0m in \u001b[0;36mpreprocess_and_save_spectrogram\u001b[0;34m(input_dir, output_dir)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Load the audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Otherwise try soundfile first, and then fall back if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFileRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# Load the target number of frames, and transpose to match librosa form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, frames, dtype, always_2d, fill_value, out)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'read'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_array_io\u001b[0;34m(self, action, array, frames)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_cdata_io\u001b[0;34m(self, action, data, ctype, frames)\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_snd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sf_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'f_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m         \u001b[0m_error_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errorcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess_and_save_spectrogram(input_dir, output_dir):\n",
        "    # Create the output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Iterate over WAV files in the input directory\n",
        "    for file_name in os.listdir(input_dir):\n",
        "        if file_name.endswith('.wav'):\n",
        "            # Load the audio file\n",
        "            file_path = os.path.join(input_dir, file_name)\n",
        "            y, sr = librosa.load(file_path)\n",
        "\n",
        "\n",
        "            # Generate the spectrogram\n",
        "            spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "            spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "            # Plot the spectrogram\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            librosa.display.specshow(spectrogram_db, sr=sr, x_axis='time', y_axis='mel')\n",
        "            plt.axis('off')  # Turn off axis\n",
        "            plt.savefig(os.path.join(output_dir, file_name[:-4] + '.png'), bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "# Preprocess real audio files\n",
        "preprocess_and_save_spectrogram('/content/drive/MyDrive/AUDIO/New Model_Main/Real_40','/content/drive/MyDrive/AUDIO/New Model_Main/test')\n",
        "\n",
        "print(\"Spectrogram images generated successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Model Building\n"
      ],
      "metadata": {
        "id": "JpN8X0kfz_1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUoYS_yECnKe"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/AUDIO/spectrogram_images/Train_Audio'\n",
        "test_dir = '/content/drive/MyDrive/AUDIO/spectrogram_images/Test_Audio'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxhN7XirOqJ1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9SlW0RrO6gJ"
      },
      "outputs": [],
      "source": [
        "def load_images_from_directory(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label, class_name in enumerate(['Fake', 'Real']):\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith('.png'):\n",
        "                img = load_img(os.path.join(class_dir, filename), target_size=(775, 385))\n",
        "                img_array = img_to_array(img)\n",
        "                images.append(img_array)\n",
        "                labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiaQLvqQPEbh"
      },
      "outputs": [],
      "source": [
        "train_audio, train_labels = load_images_from_directory(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZMnUE0wPGt6"
      },
      "outputs": [],
      "source": [
        "test_audio, test_labels = load_images_from_directory(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oM4JwnCPPIj"
      },
      "outputs": [],
      "source": [
        "train_audio = train_audio.astype('float32') / 255.0\n",
        "test_audio = test_audio.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeSwo1YtPRdi"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Oo41WnYPaTs"
      },
      "outputs": [],
      "source": [
        "train_audio, val_audio, train_labels, val_labels = train_test_split(train_audio, train_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yot1rU67PczB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmKBBT3RPt-x"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(775, 385, 3)),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxrQrU-FPys5",
        "outputId": "837d3bd2-95ba-43a3-99df-8f58d9378095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dHpWBeAP3QS",
        "outputId": "d5b292fb-ddf3-4243-e5cc-089fb5ac38c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "23/23 [==============================] - 28s 1s/step - loss: 0.3620 - accuracy: 0.7972 - val_loss: 0.2130 - val_accuracy: 0.9333\n",
            "Epoch 2/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.3727 - accuracy: 0.7833 - val_loss: 0.3386 - val_accuracy: 0.8056\n",
            "Epoch 3/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.4146 - accuracy: 0.7153 - val_loss: 0.2075 - val_accuracy: 0.9222\n",
            "Epoch 4/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.3819 - accuracy: 0.7375 - val_loss: 0.2056 - val_accuracy: 0.9278\n",
            "Epoch 5/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.4548 - accuracy: 0.7083 - val_loss: 0.2658 - val_accuracy: 0.9333\n",
            "Epoch 6/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5575 - accuracy: 0.7014 - val_loss: 0.4065 - val_accuracy: 0.9278\n",
            "Epoch 7/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.4772 - accuracy: 0.7472 - val_loss: 0.2874 - val_accuracy: 0.8444\n",
            "Epoch 8/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.4535 - accuracy: 0.7444 - val_loss: 0.3545 - val_accuracy: 0.8222\n",
            "Epoch 9/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.3837 - accuracy: 0.7736 - val_loss: 0.2997 - val_accuracy: 0.8722\n",
            "Epoch 10/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.3750 - accuracy: 0.7917 - val_loss: 0.2144 - val_accuracy: 0.9111\n",
            "Epoch 11/15\n",
            "23/23 [==============================] - 23s 989ms/step - loss: 0.3474 - accuracy: 0.8000 - val_loss: 0.2646 - val_accuracy: 0.9000\n",
            "Epoch 12/15\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.4451 - accuracy: 0.6764 - val_loss: 0.2906 - val_accuracy: 0.9222\n",
            "Epoch 13/15\n",
            "23/23 [==============================] - 23s 999ms/step - loss: 0.4131 - accuracy: 0.7194 - val_loss: 0.1706 - val_accuracy: 0.9444\n",
            "Epoch 14/15\n",
            "23/23 [==============================] - 23s 989ms/step - loss: 0.3747 - accuracy: 0.7444 - val_loss: 0.2104 - val_accuracy: 0.9278\n",
            "Epoch 15/15\n",
            "23/23 [==============================] - 23s 991ms/step - loss: 0.3984 - accuracy: 0.7361 - val_loss: 0.1407 - val_accuracy: 0.9500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79be188f2d70>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model.fit(train_audio, train_labels, validation_data=(val_audio, val_labels), epochs=15, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_audio, test_labels)\n",
        "\n",
        "print(f\"Test loss: {loss}\")\n",
        "print(f\"Test accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdtYDPw7xXlp",
        "outputId": "5e8dc926-feef-401d-9299-7346ddd112f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 6s 828ms/step - loss: 0.3528 - accuracy: 0.8909\n",
            "Test loss: 0.352847695350647\n",
            "Test accuracy: 0.8909090757369995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8761TaOP71x"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model_file = '/content/drive/MyDrive/AUDIO/New Model_Main/vgg_based.h5'"
      ],
      "metadata": {
        "id": "83si6qEZnMSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model =  load_model(Model_file)"
      ],
      "metadata": {
        "id": "yWnynqyGnTJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/drive/MyDrive/AUDIO/spectrogram_images/REAL/Abdul_kalam_part3.png'\n",
        "img = load_img(image_path, target_size=(775, 385))\n",
        "img_array = img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = img_array / 255.0"
      ],
      "metadata": {
        "id": "S47tpVcjnYK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = model.predict(img_array)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj3WRp1BocUM",
        "outputId": "25b8d82d-f487-487f-a66f-fa0b7541f358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the class probabilities\n",
        "probabilities = model.predict(img_array)[0]\n",
        "\n",
        "if len(probabilities) == 1:\n",
        "    print(f\"Probability of being Fake: {1 - probabilities[0]}\")\n",
        "    print(f\"Probability of being Real: {probabilities[0]}\")\n",
        "else:\n",
        "    print(f\"Probability of being Fake: {probabilities[0]}\")\n",
        "    print(f\"Probability of being Real: {probabilities[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP6NVSo7yUTA",
        "outputId": "afc45b95-e0df-4fc5-8865-2e90315f6532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "Probability of being Fake: 0.0011066794395446777\n",
            "Probability of being Real: 0.9988933205604553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = model.layers[0].input"
      ],
      "metadata": {
        "id": "YlXZikjFoja8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLSry_DRpBoY",
        "outputId": "482338e4-5613-4c1f-82e6-6218715b8ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 775, 385, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/AUDIO/deepfake_final.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElNp6HyFu_w2",
        "outputId": "e01d0169-00ec-4ad9-9c4d-5e7a316021ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51OljMHzzc3a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}